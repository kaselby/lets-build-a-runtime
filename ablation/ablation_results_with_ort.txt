Loaded ablation library
ONNX Runtime: v1.24.1
Running 9 configs x 21 variants

====================================================================================================
  Toy: d_model=64, n_heads=4, seq=32, batch=1
  head_dim=16, attn scratch=0.0MB
====================================================================================================
  --- Baselines ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  PT naive                   205.3us    66.5us    76.8us    61.6us  32.4% 37.4%   1.00x
  PT SDPA                    207.5us    46.4us    92.2us    61.1us  22.3% 44.4%   1.01x

  --- ONNX Runtime ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  ORT no-opt 1T               49.0us         —         —         —      —     —   0.24x
  ORT optimized 1T            43.7us         —         —         —      —     —   0.21x
  ORT optimized MT            99.1us         —         —         —      —     —   0.48x

  --- Python exec ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Numpy per-op               105.9us    35.6us    36.5us    33.6us  33.6% 34.5%   0.52x
  C per-op                   110.1us    24.8us    15.2us    68.8us  22.5% 13.9%   0.54x

  --- Incremental fusion ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  No passes                   27.1us     5.6us     2.6us    19.0us  20.8%  9.5%   0.13x
  + fold/DCE                  27.0us     5.6us     2.5us    18.8us  20.9%  9.4%   0.13x
  + BLAS absorb               22.2us     8.3us     2.6us    11.4us  37.5% 11.6%   0.11x
  + MATMUL_ADD                22.7us     8.4us     2.6us    12.0us  36.9% 11.6%   0.11x
  + BIAS_RELU                 22.0us     8.3us     2.6us    11.1us  37.8% 11.7%   0.11x

  --- Attention variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Attn: prim scalar           28.2us    13.7us     2.7us    12.0us  48.4%  9.4%   0.14x
  Attn: fused scalar          29.4us    13.9us     3.8us    11.9us  47.2% 12.9%   0.14x
  Attn: fused SIMD            23.4us     8.5us     3.7us    11.2us  36.3% 15.8%   0.11x
  Attn: fused GCD             28.1us    13.3us     3.7us    11.4us  47.4% 13.2%   0.14x
  Attn: flash GCD             29.2us    15.2us     3.7us    11.4us  52.0% 12.5%   0.14x

  --- LayerNorm variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  LN: scalar                  27.6us    13.0us     3.7us    11.2us  47.1% 13.3%   0.13x
  LN: SIMD                    25.0us    10.9us     2.3us    11.3us  43.4%  9.2%   0.12x
  LN: SIMD+GCD                28.2us    14.3us     2.8us    11.5us  50.9%  9.8%   0.14x

  --- Full optimization ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Flash + LN opt              26.2us    12.6us     2.7us    11.9us  48.2% 10.2%   0.13x

====================================================================================================
  Small: d_model=256, n_heads=4, seq=128, batch=1
  head_dim=64, attn scratch=0.3MB
====================================================================================================
  --- Baselines ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  PT naive                   806.6us   172.9us    94.4us   536.5us  21.4% 11.7%   1.00x
  PT SDPA                    681.7us    70.5us    95.8us   522.0us  10.3% 14.0%   0.85x

  --- ONNX Runtime ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  ORT no-opt 1T              394.0us         —         —         —      —     —   0.49x
  ORT optimized 1T           377.0us         —         —         —      —     —   0.47x
  ORT optimized MT           310.4us         —         —         —      —     —   0.38x

  --- Python exec ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Numpy per-op               825.1us   321.8us   127.8us   366.8us  39.0% 15.5%   1.02x
  C per-op                   508.5us    74.6us    46.4us   386.3us  14.7%  9.1%   0.63x

  --- Incremental fusion ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  No passes                  506.0us    49.4us    37.6us   417.5us   9.8%  7.4%   0.63x
  + fold/DCE                 482.5us    49.8us    36.3us   393.7us  10.3%  7.5%   0.60x
  + BLAS absorb              413.9us    75.6us    36.2us   300.4us  18.3%  8.7%   0.51x
  + MATMUL_ADD               419.3us    68.7us    40.5us   304.1us  16.4%  9.6%   0.52x
  + BIAS_RELU                416.6us    71.6us    39.5us   302.3us  17.2%  9.5%   0.52x

  --- Attention variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Attn: prim scalar          467.9us   142.1us    41.1us   297.7us  30.4%  8.8%   0.58x
  Attn: fused scalar         534.9us   160.2us    74.9us   296.9us  30.0% 14.0%   0.66x
  Attn: fused SIMD           456.5us    76.8us    74.4us   306.1us  16.8% 16.3%   0.57x
  Attn: fused GCD            489.3us    54.7us    75.5us   365.5us  11.2% 15.4%   0.61x
  Attn: flash GCD            472.2us    66.0us    73.5us   333.1us  14.0% 15.6%   0.59x

  --- LayerNorm variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  LN: scalar                 441.7us    40.7us    75.6us   326.0us   9.2% 17.1%   0.55x
  LN: SIMD                   352.0us    41.5us    20.7us   291.8us  11.8%  5.9%   0.44x
  LN: SIMD+GCD               402.2us    51.0us    42.6us   308.5us  12.7% 10.6%   0.50x

  --- Full optimization ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Flash + LN opt             441.5us    75.0us    34.0us   311.5us  17.0%  7.7%   0.55x

====================================================================================================
  Medium: d_model=512, n_heads=8, seq=256, batch=1
  head_dim=64, attn scratch=2.1MB
====================================================================================================
  --- Baselines ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  PT naive                    2.96ms   707.6us   149.5us    2.18ms  23.9%  5.1%   1.00x
  PT SDPA                     2.31ms   208.0us   128.5us    1.97ms   9.0%  5.6%   0.78x

  --- ONNX Runtime ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  ORT no-opt 1T               2.17ms         —         —         —      —     —   0.74x
  ORT optimized 1T            2.04ms         —         —         —      —     —   0.69x
  ORT optimized MT            1.63ms         —         —         —      —     —   0.55x

  --- Python exec ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Numpy per-op                5.21ms    3.00ms   511.5us    1.68ms  57.6%  9.8%   1.76x
  C per-op                    1.77ms   269.4us   116.8us    1.37ms  15.2%  6.6%   0.60x

  --- Incremental fusion ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  No passes                   2.32ms   365.8us   117.1us    1.80ms  15.8%  5.1%   0.78x
  + fold/DCE                  2.19ms   356.5us   120.9us    1.73ms  16.3%  5.5%   0.74x
  + BLAS absorb               1.95ms   515.3us   105.8us    1.31ms  26.4%  5.4%   0.66x
  + MATMUL_ADD                1.99ms   510.5us   140.9us    1.31ms  25.7%  7.1%   0.67x
  + BIAS_RELU                 1.98ms   500.8us   124.0us    1.30ms  25.3%  6.3%   0.67x

  --- Attention variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Attn: prim scalar           2.73ms    1.12ms   165.5us    1.41ms  41.2%  6.1%   0.92x
  Attn: fused scalar          2.86ms    1.11ms   311.2us    1.41ms  38.8% 10.9%   0.97x
  Attn: fused SIMD            2.08ms   521.2us   310.1us    1.25ms  25.1% 14.9%   0.70x
  Attn: fused GCD             1.73ms   184.3us   308.1us    1.25ms  10.7% 17.8%   0.59x
  Attn: flash GCD             1.84ms   256.0us   310.8us    1.26ms  13.9% 16.9%   0.62x

  --- LayerNorm variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  LN: scalar                  1.80ms   198.5us   317.4us    1.27ms  11.0% 17.6%   0.61x
  LN: SIMD                    1.77ms   258.3us   143.2us    1.37ms  14.6%  8.1%   0.60x
  LN: SIMD+GCD                1.71ms   315.0us   115.4us    1.31ms  18.4%  6.7%   0.58x

  --- Full optimization ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Flash + LN opt              1.76ms   306.4us   104.2us    1.31ms  17.4%  5.9%   0.60x

====================================================================================================
  GPT-2: d_model=768, n_heads=12, seq=512, batch=1
  head_dim=64, attn scratch=12.6MB
====================================================================================================
  --- Baselines ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  PT naive                    7.13ms    1.79ms   224.9us    4.98ms  25.0%  3.2%   1.00x
  PT SDPA                     5.62ms   683.0us   280.4us    4.66ms  12.2%  5.0%   0.79x

  --- ONNX Runtime ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  ORT no-opt 1T              10.10ms         —         —         —      —     —   1.42x
  ORT optimized 1T            9.44ms         —         —         —      —     —   1.32x
  ORT optimized MT            9.69ms         —         —         —      —     —   1.36x

  --- Python exec ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Numpy per-op               22.77ms   16.61ms    1.20ms    4.87ms  72.9%  5.3%   3.19x
  C per-op                    4.96ms   935.0us   204.0us    3.77ms  18.8%  4.1%   0.70x

  --- Incremental fusion ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  No passes                   9.92ms    4.48ms   180.6us    5.24ms  45.1%  1.8%   1.39x
  + fold/DCE                  9.90ms    4.47ms   170.9us    5.30ms  45.1%  1.7%   1.39x
  + BLAS absorb               9.32ms    5.31ms   170.1us    3.83ms  57.0%  1.8%   1.31x
  + MATMUL_ADD                9.25ms    5.22ms   172.4us    3.87ms  56.4%  1.9%   1.30x
  + BIAS_RELU                 9.18ms    5.23ms   184.3us    3.71ms  56.9%  2.0%   1.29x

  --- Attention variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Attn: prim scalar          10.76ms    6.78ms   186.5us    3.79ms  63.0%  1.7%   1.51x
  Attn: fused scalar         11.47ms    6.68ms   943.0us    3.84ms  58.3%  8.2%   1.61x
  Attn: fused SIMD            9.79ms    4.99ms   952.4us    3.88ms  51.0%  9.7%   1.37x
  Attn: fused GCD             5.58ms   889.9us   942.4us    3.73ms  16.0% 16.9%   0.78x
  Attn: flash GCD             6.03ms    1.27ms   943.0us    3.68ms  21.1% 15.6%   0.85x

  --- LayerNorm variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  LN: scalar                  5.70ms   990.5us   945.7us    3.76ms  17.4% 16.6%   0.80x
  LN: SIMD                    5.11ms   883.7us   463.0us    3.76ms  17.3%  9.1%   0.72x
  LN: SIMD+GCD                4.69ms   888.2us   148.3us    3.64ms  18.9%  3.2%   0.66x

  --- Full optimization ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Flash + LN opt              5.11ms    1.30ms   166.0us    3.65ms  25.4%  3.2%   0.72x

====================================================================================================
  1B: d_model=2048, n_heads=16, seq=512, batch=1  [large — 10 variants]
  head_dim=128, attn scratch=16.8MB
====================================================================================================
  --- Baselines ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  PT naive                   30.27ms    5.16ms   480.5us   24.74ms  17.0%  1.6%   1.00x
  PT SDPA                    27.04ms    1.89ms   508.3us   24.36ms   7.0%  1.9%   0.89x

  --- ONNX Runtime ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  ORT optimized 1T           56.67ms         —         —         —      —     —   1.87x
  ORT optimized MT           42.60ms         —         —         —      —     —   1.41x

  --- Incremental fusion ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  No passes                  33.53ms    6.69ms   245.2us   26.38ms  20.0%  0.7%   1.11x

  --- Attention variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Attn: fused scalar         34.66ms   10.01ms    2.54ms   22.18ms  28.9%  7.3%   1.14x
  Attn: fused GCD            26.52ms    1.62ms    2.54ms   22.21ms   6.1%  9.6%   0.88x
  Attn: flash GCD            27.26ms    2.29ms    2.54ms   22.31ms   8.4%  9.3%   0.90x

  --- LayerNorm variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  LN: SIMD+GCD               24.11ms    1.73ms   244.2us   22.12ms   7.2%  1.0%   0.80x

  --- Full optimization ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Flash + LN opt             24.96ms    2.40ms   234.7us   22.40ms   9.6%  0.9%   0.82x

====================================================================================================
  3B: d_model=3072, n_heads=24, seq=1024, batch=1  [large — 10 variants]
  head_dim=128, attn scratch=100.7MB
====================================================================================================
  --- Baselines ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  PT naive                  114.94ms   24.40ms   741.9us   89.94ms  21.2%  0.6%   1.00x
  PT SDPA                   100.06ms    8.71ms   880.9us   90.42ms   8.7%  0.9%   0.87x

  --- ONNX Runtime ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  ORT optimized 1T          265.68ms         —         —         —      —     —   2.31x
  ORT optimized MT          136.84ms         —         —         —      —     —   1.19x

  --- Incremental fusion ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  No passes                 139.41ms   35.33ms   600.8us  103.45ms  25.3%  0.4%   1.21x

  --- Attention variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Attn: fused scalar        152.78ms   55.90ms    7.65ms   89.94ms  36.6%  5.0%   1.33x
  Attn: fused GCD           103.98ms    7.17ms    7.62ms   88.83ms   6.9%  7.3%   0.90x
  Attn: flash GCD           108.19ms   11.68ms    7.56ms   89.05ms  10.8%  7.0%   0.94x

  --- LayerNorm variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  LN: SIMD+GCD               95.98ms    7.28ms   544.3us   88.09ms   7.6%  0.6%   0.83x

  --- Full optimization ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Flash + LN opt            100.75ms   11.64ms   573.6us   88.53ms  11.5%  0.6%   0.88x

====================================================================================================
  7B: d_model=4096, n_heads=32, seq=1024, batch=1  [large — 10 variants]
  head_dim=128, attn scratch=134.2MB
====================================================================================================
  --- Baselines ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  PT naive                  188.71ms   34.87ms   867.2us  152.48ms  18.5%  0.5%   1.00x
  PT SDPA                   165.03ms    9.98ms    1.02ms  153.26ms   6.0%  0.6%   0.87x

  --- ONNX Runtime ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  ORT optimized 1T          459.46ms         —         —         —      —     —   2.43x
  ORT optimized MT          221.68ms         —         —         —      —     —   1.17x

  --- Incremental fusion ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  No passes                 216.98ms   45.59ms   735.0us  170.82ms  21.0%  0.3%   1.15x

  --- Attention variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Attn: fused scalar        236.47ms   73.07ms   10.21ms  153.61ms  30.9%  4.3%   1.25x
  Attn: fused GCD           171.85ms    9.40ms   10.15ms  152.24ms   5.5%  5.9%   0.91x
  Attn: flash GCD           177.96ms   14.98ms   10.17ms  153.45ms   8.4%  5.7%   0.94x

  --- LayerNorm variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  LN: SIMD+GCD              164.08ms    9.72ms   700.1us  153.64ms   5.9%  0.4%   0.87x

  --- Full optimization ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Flash + LN opt            169.28ms   14.58ms   723.7us  154.06ms   8.6%  0.4%   0.90x

====================================================================================================
  7B-4K: d_model=4096, n_heads=32, seq=4096, batch=1  [large — 10 variants]
  head_dim=128, attn scratch=2147.5MB
====================================================================================================
  --- Baselines ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  PT naive                    1.25s   646.25ms    4.38ms  590.92ms  51.6%  0.3%   1.00x
  PT SDPA                   748.31ms  159.41ms    4.69ms  584.58ms  21.3%  0.6%   0.60x

  --- ONNX Runtime ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  ORT optimized 1T            2.34s          —         —         —      —     —   1.87x
  ORT optimized MT          985.85ms         —         —         —      —     —   0.79x

  --- Incremental fusion ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  No passes                   1.28s   526.93ms    2.75ms  752.08ms  41.1%  0.2%   1.02x

  --- Attention variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Attn: fused scalar          1.71s     1.09s    40.03ms  579.59ms  63.6%  2.3%   1.37x
  Attn: fused GCD           764.50ms  146.06ms   40.08ms  579.61ms  19.1%  5.2%   0.61x
  Attn: flash GCD           878.84ms  261.34ms   40.04ms  576.74ms  29.7%  4.6%   0.70x

  --- LayerNorm variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  LN: SIMD+GCD              715.28ms  137.11ms    2.62ms  577.26ms  19.2%  0.4%   0.57x

  --- Full optimization ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Flash + LN opt            850.02ms  264.68ms    2.68ms  582.80ms  31.1%  0.3%   0.68x

====================================================================================================
  1B-8K: d_model=2048, n_heads=16, seq=8192, batch=1  [large — 10 variants]
  head_dim=128, attn scratch=4295.0MB
====================================================================================================
  --- Baselines ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  PT naive                    3.14s     2.76s     5.36ms  344.83ms  87.9%  0.2%   1.00x
  PT SDPA                   593.28ms  290.05ms    4.85ms  295.83ms  48.9%  0.8%   0.19x

  --- ONNX Runtime ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  ORT optimized 1T            2.07s          —         —         —      —     —   0.66x
  ORT optimized MT          851.03ms         —         —         —      —     —   0.27x

  --- Incremental fusion ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  No passes                   1.59s     1.02s     2.65ms  565.84ms  64.0%  0.2%   0.51x

  --- Attention variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Attn: fused scalar          2.48s     2.15s    39.83ms  282.52ms  87.0%  1.6%   0.79x
  Attn: fused GCD           640.43ms  317.26ms   39.56ms  284.81ms  49.5%  6.2%   0.20x
  Attn: flash GCD           947.94ms  622.96ms   39.80ms  284.93ms  65.7%  4.2%   0.30x

  --- LayerNorm variants ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  LN: SIMD+GCD              615.64ms  329.00ms    2.67ms  284.00ms  53.4%  0.4%   0.20x

  --- Full optimization ---
  Variant                      Total      Attn        LN     Other  Attn%   LN%   vs PT
  Flash + LN opt            905.30ms  620.80ms    2.63ms  281.42ms  68.6%  0.3%   0.29x

====================================================================================================
  SUMMARY: Best compiled variant vs baselines
====================================================================================================
  Config         PT naive    PT SDPA    ORT opt  Best ours   vs PT vs SDPA  vs ORT
  ----------------------------------------------------------------------------------
  Toy             205.3us    207.5us     43.7us     22.0us   0.11x   0.11x   0.50x  (+ BIAS_RELU)
  Small           806.6us    681.7us    377.0us    352.0us   0.44x   0.52x   0.93x  (LN: SIMD)
  Medium           2.96ms     2.31ms     2.04ms     1.71ms   0.58x   0.74x   0.84x  (LN: SIMD+GCD)
  GPT-2            7.13ms     5.62ms     9.44ms     4.69ms   0.66x   0.83x   0.50x  (LN: SIMD+GCD)
  1B              30.27ms    27.04ms    56.67ms    24.11ms   0.80x   0.89x   0.43x  (LN: SIMD+GCD)
  3B             114.94ms   100.06ms   265.68ms    95.98ms   0.83x   0.96x   0.36x  (LN: SIMD+GCD)
  7B             188.71ms   165.03ms   459.46ms   164.08ms   0.87x   0.99x   0.36x  (LN: SIMD+GCD)
  7B-4K            1.25s    748.31ms     2.34s    715.28ms   0.57x   0.96x   0.31x  (LN: SIMD+GCD)
  1B-8K            3.14s    593.28ms     2.07s    615.64ms   0.20x   1.04x   0.30x  (LN: SIMD+GCD)
